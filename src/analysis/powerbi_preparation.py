"""
Preparaci√≥n de datos para Power BI.

Este m√≥dulo prepara los datos optimizados para Power BI,
incluyendo consultas SQL especializadas y transformaciones
de datos para visualizaciones efectivas.
"""

import pandas as pd
import sqlite3
import logging
from pathlib import Path
from typing import Dict, List, Tuple
import json
from datetime import datetime
import numpy as np

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PowerBIDataPreparator:
    """
    Clase para preparar datos optimizados para Power BI.
    """
    
    def __init__(self, db_path: str = "data/processed/sales_analysis.db"):
        """
        Inicializar el preparador de datos para Power BI.
        
        Args:
            db_path: Ruta a la base de datos SQLite
        """
        self.db_path = db_path
        self.connection = None
        
    def connect_db(self) -> sqlite3.Connection:
        """Conectar a la base de datos."""
        try:
            self.connection = sqlite3.connect(self.db_path)
            logger.info("Conectado a la base de datos SQLite")
            return self.connection
        except Exception as e:
            logger.error(f"Error al conectar a la base de datos: {e}")
            raise
    
    def create_powerbi_datasets(self) -> Dict[str, pd.DataFrame]:
        """
        Crear datasets optimizados para Power BI.
        
        Returns:
            Diccionario con los datasets principales
        """
        logger.info("Creando datasets optimizados para Power BI...")
        
        datasets = {}
        
        # 1. Dataset principal de ventas
        datasets['sales_fact'] = self._create_sales_fact_table()
        
        # 2. Dimensiones
        datasets['dim_customers'] = self._create_customer_dimension()
        datasets['dim_products'] = self._create_product_dimension()
        datasets['dim_countries'] = self._create_country_dimension()
        datasets['dim_dates'] = self._create_date_dimension()
        
        # 3. M√©tricas calculadas
        datasets['sales_metrics'] = self._create_sales_metrics()
        datasets['customer_metrics'] = self._create_customer_metrics()
        datasets['product_metrics'] = self._create_product_metrics()
        
        # 4. An√°lisis temporal
        datasets['temporal_analysis'] = self._create_temporal_analysis()
        
        # 5. An√°lisis geogr√°fico
        datasets['geographic_analysis'] = self._create_geographic_analysis()
        
        logger.info(f"Se crearon {len(datasets)} datasets para Power BI")
        return datasets
    
    def _create_sales_fact_table(self) -> pd.DataFrame:
        """Crear tabla de hechos de ventas optimizada."""
        query = """
        SELECT 
            ORDERNUMBER,
            ORDERDATE,
            CUSTOMERNAME,
            PRODUCTCODE,
            PRODUCTLINE,
            COUNTRY,
            CITY,
            SALES,
            QUANTITYORDERED,
            PRICEEACH,
            STATUS,
            DEALSIZE,
            YEAR,
            MONTH,
            QUARTER,
            DAY_OF_WEEK,
            IS_WEEKEND,
            SALES_PER_UNIT,
            TOTAL_ORDER_VALUE,
            CUSTOMER_SEGMENT,
            PRODUCT_CATEGORY
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        ORDER BY ORDERDATE DESC
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"Tabla de hechos creada: {df.shape[0]} registros")
        return df
    
    def _create_customer_dimension(self) -> pd.DataFrame:
        """Crear dimensi√≥n de clientes."""
        query = """
        SELECT DISTINCT
            CUSTOMERNAME,
            COUNTRY,
            CITY,
            CUSTOMER_SEGMENT,
            COUNT(*) as total_orders,
            SUM(SALES) as total_sales,
            AVG(SALES) as avg_order_value,
            MIN(ORDERDATE) as first_order_date,
            MAX(ORDERDATE) as last_order_date
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        GROUP BY CUSTOMERNAME, COUNTRY, CITY, CUSTOMER_SEGMENT
        ORDER BY total_sales DESC
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"Dimensi√≥n de clientes creada: {df.shape[0]} clientes √∫nicos")
        return df
    
    def _create_product_dimension(self) -> pd.DataFrame:
        """Crear dimensi√≥n de productos."""
        query = """
        SELECT DISTINCT
            PRODUCTCODE,
            PRODUCTLINE,
            PRODUCT_CATEGORY,
            COUNT(*) as total_orders,
            SUM(SALES) as total_sales,
            SUM(QUANTITYORDERED) as total_quantity,
            AVG(PRICEEACH) as avg_price,
            AVG(SALES) as avg_order_value
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        GROUP BY PRODUCTCODE, PRODUCTLINE, PRODUCT_CATEGORY
        ORDER BY total_sales DESC
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"Dimensi√≥n de productos creada: {df.shape[0]} productos √∫nicos")
        return df
    
    def _create_country_dimension(self) -> pd.DataFrame:
        """Crear dimensi√≥n de pa√≠ses."""
        query = """
        SELECT DISTINCT
            COUNTRY,
            COUNT(DISTINCT CUSTOMERNAME) as unique_customers,
            COUNT(*) as total_orders,
            SUM(SALES) as total_sales,
            AVG(SALES) as avg_order_value,
            COUNT(DISTINCT PRODUCTCODE) as unique_products
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        GROUP BY COUNTRY
        ORDER BY total_sales DESC
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"Dimensi√≥n de pa√≠ses creada: {df.shape[0]} pa√≠ses")
        return df
    
    def _create_date_dimension(self) -> pd.DataFrame:
        """Crear dimensi√≥n de fechas."""
        query = """
        SELECT DISTINCT
            ORDERDATE,
            YEAR,
            MONTH,
            QUARTER,
            DAY_OF_WEEK,
            IS_WEEKEND,
            CASE 
                WHEN MONTH IN (12, 1, 2) THEN 'Winter'
                WHEN MONTH IN (3, 4, 5) THEN 'Spring'
                WHEN MONTH IN (6, 7, 8) THEN 'Summer'
                ELSE 'Fall'
            END as SEASON
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        ORDER BY ORDERDATE
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"Dimensi√≥n de fechas creada: {df.shape[0]} fechas √∫nicas")
        return df
    
    def _create_sales_metrics(self) -> pd.DataFrame:
        """Crear m√©tricas de ventas agregadas."""
        query = """
        WITH daily_sales AS (
            SELECT 
                ORDERDATE,
                SUM(SALES) as daily_sales,
                COUNT(*) as daily_orders,
                COUNT(DISTINCT CUSTOMERNAME) as daily_customers
            FROM sales_data
            WHERE STATUS != 'Cancelled'
            GROUP BY ORDERDATE
        ),
        monthly_sales AS (
            SELECT 
                YEAR,
                MONTH,
                SUM(SALES) as monthly_sales,
                COUNT(*) as monthly_orders,
                COUNT(DISTINCT CUSTOMERNAME) as monthly_customers
            FROM sales_data
            WHERE STATUS != 'Cancelled'
            GROUP BY YEAR, MONTH
        )
        SELECT 
            'Daily' as aggregation_level,
            ORDERDATE as date,
            daily_sales,
            daily_orders,
            daily_customers,
            daily_sales / NULLIF(daily_orders, 0) as avg_order_value
        FROM daily_sales
        UNION ALL
        SELECT 
            'Monthly' as aggregation_level,
            DATE(YEAR || '-' || printf('%02d', MONTH) || '-01') as date,
            monthly_sales,
            monthly_orders,
            monthly_customers,
            monthly_sales / NULLIF(monthly_orders, 0) as avg_order_value
        FROM monthly_sales
        ORDER BY date
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"M√©tricas de ventas creadas: {df.shape[0]} registros")
        return df
    
    def _create_customer_metrics(self) -> pd.DataFrame:
        """Crear m√©tricas de clientes."""
        query = """
        WITH customer_rankings AS (
            SELECT 
                CUSTOMERNAME,
                COUNTRY,
                COUNT(*) as order_count,
                SUM(SALES) as total_sales,
                AVG(SALES) as avg_order_value,
                ROW_NUMBER() OVER (ORDER BY SUM(SALES) DESC) as sales_rank,
                ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) as order_rank
            FROM sales_data
            WHERE STATUS != 'Cancelled'
            GROUP BY CUSTOMERNAME, COUNTRY
        )
        SELECT 
            *,
            CASE 
                WHEN sales_rank <= 10 THEN 'Top 10'
                WHEN sales_rank <= 50 THEN 'Top 50'
                WHEN sales_rank <= 100 THEN 'Top 100'
                ELSE 'Others'
            END as customer_tier
        FROM customer_rankings
        ORDER BY sales_rank
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"M√©tricas de clientes creadas: {df.shape[0]} clientes")
        return df
    
    def _create_product_metrics(self) -> pd.DataFrame:
        """Crear m√©tricas de productos."""
        query = """
        WITH product_performance AS (
            SELECT 
                PRODUCTCODE,
                PRODUCTLINE,
                COUNT(*) as order_count,
                SUM(SALES) as total_sales,
                SUM(QUANTITYORDERED) as total_quantity,
                AVG(PRICEEACH) as avg_price,
                ROW_NUMBER() OVER (ORDER BY SUM(SALES) DESC) as sales_rank,
                ROW_NUMBER() OVER (ORDER BY SUM(QUANTITYORDERED) DESC) as quantity_rank
            FROM sales_data
            WHERE STATUS != 'Cancelled'
            GROUP BY PRODUCTCODE, PRODUCTLINE
        )
        SELECT 
            *,
            CASE 
                WHEN sales_rank <= 10 THEN 'Top 10'
                WHEN sales_rank <= 25 THEN 'Top 25'
                WHEN sales_rank <= 50 THEN 'Top 50'
                ELSE 'Others'
            END as product_tier
        FROM product_performance
        ORDER BY sales_rank
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"M√©tricas de productos creadas: {df.shape[0]} productos")
        return df
    
    def _create_temporal_analysis(self) -> pd.DataFrame:
        """Crear an√°lisis temporal detallado."""
        query = """
        SELECT 
            YEAR,
            MONTH,
            QUARTER,
            DAY_OF_WEEK,
            COUNT(*) as order_count,
            SUM(SALES) as total_sales,
            COUNT(DISTINCT CUSTOMERNAME) as unique_customers,
            COUNT(DISTINCT PRODUCTCODE) as unique_products,
            AVG(SALES) as avg_order_value,
            SUM(QUANTITYORDERED) as total_quantity
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        GROUP BY YEAR, MONTH, QUARTER, DAY_OF_WEEK
        ORDER BY YEAR, MONTH, DAY_OF_WEEK
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"An√°lisis temporal creado: {df.shape[0]} registros")
        return df
    
    def _create_geographic_analysis(self) -> pd.DataFrame:
        """Crear an√°lisis geogr√°fico."""
        query = """
        SELECT 
            COUNTRY,
            CITY,
            COUNT(*) as order_count,
            SUM(SALES) as total_sales,
            COUNT(DISTINCT CUSTOMERNAME) as unique_customers,
            COUNT(DISTINCT PRODUCTCODE) as unique_products,
            AVG(SALES) as avg_order_value,
            SUM(QUANTITYORDERED) as total_quantity
        FROM sales_data
        WHERE STATUS != 'Cancelled'
        GROUP BY COUNTRY, CITY
        ORDER BY total_sales DESC
        """
        
        df = pd.read_sql_query(query, self.connection)
        logger.info(f"An√°lisis geogr√°fico creado: {df.shape[0]} ubicaciones")
        return df
    
    def export_to_excel(self, datasets: Dict[str, pd.DataFrame], output_path: str = "data/final/powerbi_data.xlsx"):
        """
        Exportar datasets a Excel para Power BI.
        
        Args:
            datasets: Diccionario con los datasets
            output_path: Ruta del archivo Excel de salida
        """
        logger.info(f"Exportando datasets a Excel: {output_path}")
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            for sheet_name, df in datasets.items():
                # Limitar el nombre de la hoja a 31 caracteres (l√≠mite de Excel)
                sheet_name = sheet_name[:31]
                df.to_excel(writer, sheet_name=sheet_name, index=False)
                logger.info(f"Hoja '{sheet_name}' exportada: {df.shape[0]} filas, {df.shape[1]} columnas")
        
        logger.info(f"Archivo Excel creado exitosamente: {output_path}")
    
    def export_to_csv(self, datasets: Dict[str, pd.DataFrame], output_dir: str = "data/final/powerbi_csv/"):
        """
        Exportar datasets a archivos CSV separados.
        
        Args:
            datasets: Diccionario con los datasets
            output_dir: Directorio de salida para los archivos CSV
        """
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        logger.info(f"Exportando datasets a CSV en: {output_dir}")
        
        for dataset_name, df in datasets.items():
            csv_path = Path(output_dir) / f"{dataset_name}.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8')
            logger.info(f"CSV '{dataset_name}' exportado: {df.shape[0]} filas, {df.shape[1]} columnas")
        
        logger.info(f"Archivos CSV creados exitosamente en: {output_dir}")
    
    def create_powerbi_queries(self) -> Dict[str, str]:
        """
        Crear consultas SQL optimizadas para Power BI.
        
        Returns:
            Diccionario con las consultas SQL
        """
        queries = {
            'sales_overview': """
                SELECT 
                    DATE(ORDERDATE) as order_date,
                    SUM(SALES) as daily_sales,
                    COUNT(*) as daily_orders,
                    COUNT(DISTINCT CUSTOMERNAME) as daily_customers
                FROM sales_data
                WHERE STATUS != 'Cancelled'
                GROUP BY DATE(ORDERDATE)
                ORDER BY order_date
            """,
            
            'top_customers': """
                SELECT 
                    CUSTOMERNAME,
                    COUNTRY,
                    SUM(SALES) as total_sales,
                    COUNT(*) as order_count,
                    AVG(SALES) as avg_order_value
                FROM sales_data
                WHERE STATUS != 'Cancelled'
                GROUP BY CUSTOMERNAME, COUNTRY
                ORDER BY total_sales DESC
                LIMIT 20
            """,
            
            'product_performance': """
                SELECT 
                    PRODUCTLINE,
                    PRODUCTCODE,
                    SUM(SALES) as total_sales,
                    SUM(QUANTITYORDERED) as total_quantity,
                    COUNT(*) as order_count
                FROM sales_data
                WHERE STATUS != 'Cancelled'
                GROUP BY PRODUCTLINE, PRODUCTCODE
                ORDER BY total_sales DESC
            """,
            
            'geographic_sales': """
                SELECT 
                    COUNTRY,
                    CITY,
                    SUM(SALES) as total_sales,
                    COUNT(*) as order_count,
                    COUNT(DISTINCT CUSTOMERNAME) as unique_customers
                FROM sales_data
                WHERE STATUS != 'Cancelled'
                GROUP BY COUNTRY, CITY
                ORDER BY total_sales DESC
            """,
            
            'monthly_trends': """
                SELECT 
                    YEAR,
                    MONTH,
                    SUM(SALES) as monthly_sales,
                    COUNT(*) as monthly_orders,
                    AVG(SALES) as avg_order_value
                FROM sales_data
                WHERE STATUS != 'Cancelled'
                GROUP BY YEAR, MONTH
                ORDER BY YEAR, MONTH
            """
        }
        
        return queries
    
    def generate_powerbi_guide(self, output_path: str = "data/final/powerbi_guide.md"):
        """
        Generar gu√≠a para Power BI.
        
        Args:
            output_path: Ruta del archivo de gu√≠a
        """
        guide_content = """# Gu√≠a para Power BI - An√°lisis de Ventas

## üìä Datasets Disponibles

### 1. **sales_fact** - Tabla Principal de Hechos
- **Descripci√≥n**: Datos de ventas detallados
- **Registros**: ~2,800 ventas
- **Columnas clave**: ORDERNUMBER, ORDERDATE, CUSTOMERNAME, PRODUCTCODE, SALES

### 2. **dim_customers** - Dimensi√≥n de Clientes
- **Descripci√≥n**: Informaci√≥n agregada por cliente
- **Registros**: ~350 clientes √∫nicos
- **Columnas clave**: CUSTOMERNAME, COUNTRY, total_sales, customer_tier

### 3. **dim_products** - Dimensi√≥n de Productos
- **Descripci√≥n**: Informaci√≥n agregada por producto
- **Registros**: ~100 productos √∫nicos
- **Columnas clave**: PRODUCTCODE, PRODUCTLINE, total_sales, product_tier

### 4. **sales_metrics** - M√©tricas de Ventas
- **Descripci√≥n**: M√©tricas agregadas por d√≠a y mes
- **Registros**: ~200 registros temporales
- **Columnas clave**: date, daily_sales, daily_orders, avg_order_value

## üéØ Visualizaciones Recomendadas

### Dashboard Principal
1. **KPI Cards**:
   - Total de Ventas
   - N√∫mero de √ìrdenes
   - Clientes √önicos
   - Valor Promedio por Orden

2. **Gr√°ficos de L√≠nea**:
   - Ventas por Mes
   - √ìrdenes por D√≠a de la Semana
   - Tendencia de Clientes

3. **Gr√°ficos de Barras**:
   - Top 10 Clientes por Ventas
   - Top 10 Productos por Ventas
   - Ventas por Pa√≠s

4. **Mapa**:
   - Ventas por Pa√≠s/Ciudad

### Dashboard de An√°lisis Detallado
1. **Tabla de Clientes**:
   - Ranking de clientes
   - M√©tricas por cliente
   - Segmentaci√≥n

2. **An√°lisis de Productos**:
   - Performance por l√≠nea de producto
   - Cantidad vs. Valor
   - Productos m√°s vendidos

3. **An√°lisis Temporal**:
   - Patrones estacionales
   - Comparaci√≥n a√±o a a√±o
   - An√°lisis por trimestre

## üîó Relaciones en Power BI

### Modelo de Datos
```
sales_fact (1) ‚Üí (1) dim_customers [CUSTOMERNAME]
sales_fact (1) ‚Üí (1) dim_products [PRODUCTCODE]
sales_fact (1) ‚Üí (1) dim_dates [ORDERDATE]
sales_fact (1) ‚Üí (1) dim_countries [COUNTRY]
```

### Configuraci√≥n de Relaciones
1. **sales_fact.CUSTOMERNAME** ‚Üí **dim_customers.CUSTOMERNAME**
2. **sales_fact.PRODUCTCODE** ‚Üí **dim_products.PRODUCTCODE**
3. **sales_fact.ORDERDATE** ‚Üí **dim_dates.ORDERDATE**
4. **sales_fact.COUNTRY** ‚Üí **dim_countries.COUNTRY**

## üìà Medidas DAX Recomendadas

### Medidas B√°sicas
```dax
Total Sales = SUM(sales_fact[SALES])
Total Orders = COUNTROWS(sales_fact)
Unique Customers = DISTINCTCOUNT(sales_fact[CUSTOMERNAME])
Average Order Value = DIVIDE([Total Sales], [Total Orders])
```

### Medidas Avanzadas
```dax
Sales Growth % = 
VAR CurrentSales = [Total Sales]
VAR PreviousSales = CALCULATE([Total Sales], DATEADD(dim_dates[ORDERDATE], -1, MONTH))
RETURN
DIVIDE(CurrentSales - PreviousSales, PreviousSales)

Customer Retention = 
VAR CurrentCustomers = [Unique Customers]
VAR PreviousCustomers = CALCULATE([Unique Customers], DATEADD(dim_dates[ORDERDATE], -1, MONTH))
RETURN
DIVIDE(CurrentCustomers, PreviousCustomers)
```

## üé® Configuraci√≥n de Tema

### Colores Recomendados
- **Primario**: #1f77b4 (Azul)
- **Secundario**: #ff7f0e (Naranja)
- **√âxito**: #2ca02c (Verde)
- **Advertencia**: #d62728 (Rojo)
- **Neutro**: #7f7f7f (Gris)

### Tipograf√≠a
- **T√≠tulos**: Segoe UI Bold, 16pt
- **Subt√≠tulos**: Segoe UI Semibold, 14pt
- **Texto**: Segoe UI Regular, 12pt

## üìã Checklist de Implementaci√≥n

- [ ] Importar datasets desde Excel/CSV
- [ ] Configurar relaciones entre tablas
- [ ] Crear medidas DAX b√°sicas
- [ ] Dise√±ar dashboard principal
- [ ] Crear visualizaciones recomendadas
- [ ] Configurar filtros y segmentadores
- [ ] Aplicar tema y colores
- [ ] Probar interactividad
- [ ] Optimizar rendimiento
- [ ] Documentar dashboard

## üöÄ Pr√≥ximos Pasos

1. **An√°lisis Predictivo**: Implementar modelos de ML
2. **Alertas**: Configurar notificaciones autom√°ticas
3. **Automatizaci√≥n**: Actualizaci√≥n autom√°tica de datos
4. **M√≥vil**: Optimizar para dispositivos m√≥viles
5. **Colaboraci√≥n**: Compartir con stakeholders

---
*Generado autom√°ticamente por el sistema de an√°lisis de datos*
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        logger.info(f"Gu√≠a de Power BI generada: {output_path}")
    
    def close_connection(self):
        """Cerrar conexi√≥n a la base de datos."""
        if self.connection:
            self.connection.close()
            logger.info("Conexi√≥n a la base de datos cerrada")


def main():
    """Funci√≥n principal para preparar datos para Power BI."""
    print("üöÄ Preparando datos para Power BI...")
    
    # Inicializar preparador
    preparator = PowerBIDataPreparator()
    
    try:
        # Conectar a la base de datos
        preparator.connect_db()
        
        # Crear datasets
        datasets = preparator.create_powerbi_datasets()
        
        # Exportar a Excel
        preparator.export_to_excel(datasets)
        
        # Exportar a CSV
        preparator.export_to_csv(datasets)
        
        # Generar gu√≠a
        preparator.generate_powerbi_guide()
        
        # Crear consultas SQL
        queries = preparator.create_powerbi_queries()
        
        # Guardar consultas SQL
        queries_path = "data/final/powerbi_queries.json"
        with open(queries_path, 'w', encoding='utf-8') as f:
            json.dump(queries, f, indent=2, ensure_ascii=False)
        
        print("‚úÖ Datos preparados exitosamente para Power BI!")
        print(f"üìä Archivos generados:")
        print(f"   - Excel: data/final/powerbi_data.xlsx")
        print(f"   - CSV: data/final/powerbi_csv/")
        print(f"   - Gu√≠a: data/final/powerbi_guide.md")
        print(f"   - Consultas: data/final/powerbi_queries.json")
        
    except Exception as e:
        logger.error(f"Error en la preparaci√≥n de datos: {e}")
        raise
    finally:
        preparator.close_connection()


if __name__ == "__main__":
    main()

